{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qorgh\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization code\n",
    "standardizator = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels이나 실제론 gray scale\n",
    "                                         std=(0.5, 0.5, 0.5))])  # 3 for RGB channels이나 실제론 gray scale\n",
    "\n",
    "# MNIST dataset\n",
    "train_data = dsets.MNIST(root='data/', train=True, transform=standardizator, download=True)\n",
    "test_data  = dsets.MNIST(root='data/', train=False, transform=standardizator, download=True)\n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "test_data_loader  = torch.utils.data.DataLoader(test_data, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def imshow(img):\n",
    "    img = (img+1)/2    \n",
    "    img = img.squeeze()\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow(np_img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def imshow_grid(img): \n",
    "    img = utils.make_grid(img.cpu().detach())\n",
    "    img = (img+1)/2\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()\n",
    "    \n",
    "example_mini_batch_img, example_mini_batch_label  = next(iter(train_data_loader))\n",
    "imshow_grid(example_mini_batch_img[0:16,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_noise  = 100\n",
    "d_hidden = 256\n",
    "\n",
    "def sample_z(batch_size = 1, d_noise=100):\n",
    "    return torch.randn(batch_size, d_noise, device=device)\n",
    "\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(d_noise, d_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(d_hidden,d_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(d_hidden, 28*28),\n",
    "    nn.Tanh()\n",
    ").to(device)\n",
    "\n",
    "# 노이즈 생성하기\n",
    "z = sample_z()\n",
    "# 가짜 이미지 생성하기\n",
    "img_fake = G(z).view(-1,28,28)\n",
    "# 이미지 출력하기\n",
    "imshow(img_fake.squeeze().cpu().detach())\n",
    "\n",
    "# Batch SIze만큼 노이즈 생성하여 그리드로 출력하기\n",
    "z = sample_z(batch_size)\n",
    "img_fake = G(z)\n",
    "imshow_grid(img_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = nn.Sequential(\n",
    "    nn.Linear(28*28, d_hidden),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(d_hidden, d_hidden),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(d_hidden, 1),\n",
    "    nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "print(G(z).shape)\n",
    "print(D(G(z)).shape)\n",
    "print(D(G(z)[0:5]).transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Size([200, 784])\n",
    "torch.Size([200, 1])\n",
    "tensor([[0.4965, 0.4984, 0.4948, 0.4938, 0.4918]], device='cuda:0',\n",
    "       grad_fn=<TransposeBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "def run_epoch(generator, discriminator, _optimizer_g, _optimizer_d):\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    for img_batch, label_batch in train_data_loader:\n",
    "        \n",
    "        img_batch, label_batch = img_batch.to(device), label_batch.to(device) \n",
    "\n",
    "        # ================================================  #\n",
    "        # maximize V(discriminator,generator) = optimize discriminator (setting k to be 1)  #\n",
    "        # ================================================  #\n",
    "\n",
    "        # init optimizer\n",
    "        _optimizer_d.zero_grad()\n",
    "\n",
    "        p_real = discriminator(img_batch.view(-1, 28*28))\n",
    "        p_fake = discriminator(generator(sample_z(batch_size, d_noise)))\n",
    "\n",
    "        # ================================================  #\n",
    "        #    Loss computation (soley based on the paper)    #\n",
    "        # ================================================  #\n",
    "        loss_real = -1 * torch.log(p_real)   # -1 for gradient ascending\n",
    "        loss_fake = -1 * torch.log(1.-p_fake) # -1 for gradient ascending\n",
    "        loss_d    = (loss_real + loss_fake).mean()\n",
    "        \n",
    "        # ================================================  #\n",
    "        #     Loss computation (based on Cross Entropy)     #\n",
    "        # ================================================  #\n",
    "        # loss_d = criterion(p_real, torch.ones_like(p_real).to(device)) + \\    #\n",
    "        #          criterion(p_fake, torch.zeros_like(p_real).to(device))       #\n",
    "        \n",
    "        # Update parameters\n",
    "        loss_d.backward()\n",
    "        _optimizer_d.step()\n",
    "\n",
    "        # ================================================  #\n",
    "        #        minimize V(discriminator,generator)        #\n",
    "        # ================================================  #\n",
    "\n",
    "        # init optimizer\n",
    "        _optimizer_g.zero_grad()\n",
    "\n",
    "        p_fake = discriminator(generator(sample_z(batch_size, d_noise)))\n",
    "                \n",
    "        # ================================================  #\n",
    "        #    Loss computation (soley based on the paper)    #\n",
    "        # ================================================  #\n",
    "        \n",
    "        # instead of: torch.log(1.-p_fake).mean() <- explained in Section 3\n",
    "        loss_g = -1 * torch.log(p_fake).mean() \n",
    "\n",
    "        # ================================================  #\n",
    "        #     Loss computation (based on Cross Entropy)     #\n",
    "        # ================================================  #\n",
    "        # loss_g = criterion(p_fake, torch.ones_like(p_fake).to(device)) #\n",
    "\n",
    "        loss_g.backward()\n",
    "   \n",
    "        # Update parameters\n",
    "        _optimizer_g.step()\n",
    "          \n",
    "def evaluate_model(generator, discriminator):\n",
    "    \n",
    "    p_real, p_fake = 0.,0.\n",
    "    \n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "        \n",
    "    for img_batch, label_batch in test_data_loader:\n",
    "        \n",
    "        img_batch, label_batch = img_batch.to(device), label_batch.to(device) \n",
    "        \n",
    "        with torch.autograd.no_grad():\n",
    "            p_real += (torch.sum(discriminator(img_batch.view(-1, 28*28))).item())/10000.\n",
    "            p_fake += (torch.sum(discriminator(generator(sample_z(batch_size, d_noise)))).item())/10000.\n",
    "            \n",
    "            \n",
    "    return p_real, p_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(model):\n",
    "    for p in model.parameters():\n",
    "        if(p.dim() > 1):\n",
    "            nn.init.xavier_normal_(p)\n",
    "        else:\n",
    "            nn.init.uniform_(p, 0.1, 0.2)\n",
    "\n",
    "init_params(G)\n",
    "init_params(D)\n",
    "\n",
    "optimizer_g = optim.Adam(G.parameters(), lr = 0.0002)\n",
    "optimizer_d = optim.Adam(D.parameters(), lr = 0.0002)\n",
    "\n",
    "p_real_trace = []\n",
    "p_fake_trace = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    \n",
    "    run_epoch(G, D, optimizer_g, optimizer_d)\n",
    "    p_real, p_fake = evaluate_model(G,D)\n",
    "    \n",
    "    p_real_trace.append(p_real)\n",
    "    p_fake_trace.append(p_fake) \n",
    "    \n",
    "    if((epoch+1)% 50 == 0):\n",
    "        print('(epoch %i/200) p_real: %f, p_g: %f' % (epoch+1, p_real, p_fake))\n",
    "        imshow_grid(G(sample_z(16)).view(-1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(epoch 50/200) p_real: 0.739482, p_g: 0.231452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(epoch 100/200) p_real: 0.632178, p_g: 0.219324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(epoch 150/200) p_real: 0.606782, p_g: 0.295501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(epoch 200/200) p_real: 0.619400, p_g: 0.373423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(p_fake_trace, label='D(x_generated)')\n",
    "plt.plot(p_real_trace, label='D(x_real)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_loader = torch.utils.data.DataLoader(test_data, 16, True)\n",
    "img_vis, label_vis   = next(iter(vis_loader))\n",
    "imshow_grid(img_vis)\n",
    "\n",
    "imshow_grid(G(sample_z(16,100)).view(-1, 1, 28, 28))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
